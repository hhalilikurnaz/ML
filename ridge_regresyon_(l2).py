# -*- coding: utf-8 -*-
"""Ridge Regresyon (L2).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PdufMKQy6LvO4An17yI4GiqAUYH_NLdu
"""

#Ridge regresyon overfitting (Aşırı öğrenme durumları için kullanılır)

#Ridge regresyon sayesinde bias ve varyans arasındaki dengeyi sağlayabiliriz

#Ridge regresyonda katsayılar üzerinde regülasyon yapılıyor

#Ridge regresyonda katsayılar küçülür ama sıfır olmaz.Features öz nitelik azalmaz

#Ridge regresyonda cezalar (küçülmeler) karesi ile orantılı

#Ridge regresyon l2 olarak da adlandırılıyor

# y = a1*x1+a2*x2+...    + b  + alfa *(katsayılartoplamı)**2
# bu a katsayılarında bir küçülme gerekiyor
#a artıkça doğru x eksenine paralelleşiyor


# 50 = 40 + 10 +0
# 50= 30 + 10 + 10

import pandas as pd ; import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression,Ridge

df =pd.read_csv("student.csv")
 df.head(3)

df=df.drop(['number_courses'],axis=1)
df.head(3)

y=df['Marks']
x=df.drop(['Marks'],axis=1)

plt.style.use('fivethirtyeight')
#grafiğin türü
plt.figure(figsize=(8,8))
#grafiğin boyutu
plt.scatter(x,y)
#grafiğin parametreleri
plt.show()

lr=LinearRegression()
model=lr.fit(x,y)
model.score(x,y)

alfalar=[1,10,20,100,200]
for a in alfalar:
  r=Ridge(alpha=a)
  modelr=r.fit(x,y)
  skor=modelr.score(x,y)
  print("Skor",skor)
  print("Katsayı",modelr.coef_)

#şunu gördük alfa arttıkça katsayı azaldı