# -*- coding: utf-8 -*-
"""Decision Tree Classifier/Random Forest Classifier/Kalp Krizi Riski.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PpxwhyEqCwhceZLhNOQHG3e56rO9WCH7
"""

#Desicion Tree = Karar Ağacaı demek
import pandas as pd ; import numpy as np
from sklearn.tree import DecisionTreeClassifier,export_graphviz
from sklearn.model_selection import train_test_split
#karar ağacı sınıflandırması kütüphanesi

import graphviz

"""DecisionTree Nasıl Çalışıyor
Size Soru soruyor cevabınıza göre çalışıyor
Benim features'lerimi yani x'lerimi yani bağımsız değişkenlerimi sorucak size
Overfitting'e yakın bir modeldir yani cevapları ezberliyebiliyor



"""

df=pd.read_csv("heart.csv")
df.head(3)

y=df['output']
x=df.drop(['output'],axis=1)

x_train,x_test,y_train,y_test=train_test_split(x,y,train_size=0.7,random_state=6)

tree=DecisionTreeClassifier()
model=tree.fit(x_train,y_train)

model.score(x_test,y_test)

#Bu modeli görselleştireceğiz şimdi
dot=export_graphviz(model,feature_names=x.columns,filled=True)
image=graphviz.Source(dot)
image

#birden fazla modelin birleşmesiyle oluşan modeller ensemble model oluyor
#Kategorisel veri çokta RandomForestClassifier modeli daha iyi sonuçlar veriyor


from sklearn.ensemble import RandomForestClassifier

#RandomForestClassifier'ın parametreleri var mesela n_estimators ormanda kaç ağac olsun defult 100 ama ben sayıyı verebiliyorum
#Başka parametresi max_depth derinlik ne kadar derinlere inerim fazla derinlere inersem ezber oranı artıyor
#Bir de criterion var ya gini ya da entropy bunlar katsayı
forest=RandomForestClassifier()
model=forest.fit(x,y)
model.score(x,y)
#Yine ezberlemiş overfitting yapmış

forest=RandomForestClassifier(n_estimators=400,max_depth=4,criterion="entropy")
model=forest.fit(x_train,y_train)
model.score(x_test,y_test)